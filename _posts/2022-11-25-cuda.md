---
layout: post
title:  "cuda"
date:   2022-11-20 08:30:00 +0800
categories: [Lan]
excerpt: cuda
tags:
  -  
  - cuda
  - 
---

# 关于库的`compile with cuda`



### flann
1. 



1. 由于硬件设计，调度会以一整个线程束为单位进行。因此应该充分利用线程束中的所有线程进行计算，以尽可能少的线程束的数量，同时提高硬件的使用率。
2. 在CPU编程中，我们学过空间局部性与时间局部性。对全局内存的访问要尽量进行合并访问与存储，让对内存的访问更加集中(访问的内存地址尽量连续)，这样才能达到最大的带宽。
3. 那些可以到达__syncthreads()的线程需要其他可以到达该点的线程，而不是等待块内所有其他线程。


# 内存模型

时间局部性，就是一个内存位置的数据某时刻被引用，那么在此时刻附近也很有可能被引用，随时间流逝，该数据被引用的可能性逐渐降低。
空间局部性，如果某一内存位置的数据被使用，那么附近的数据也有可能被使用。

### 寄存器
在核函数中定义的有常数长度的数组也是在寄存器中分配地址的。寄存器对于每个线程是私有的，寄存器变量的声明周期和核函数一致。寄存器是SM中的稀缺资源，一个线程如果使用更少的寄存器，那么就会有更多的常驻线程块，SM上并发的线程块越多。、

关键字 `__lauch_bounds__(maxThreadaPerBlock,minBlocksPerMultiprocessor)` `__share__`

编译选项中加入 `-maxrregcount=32`

核函数中符合存储在寄存器中但不能进入被核函数分配的寄存器空间中的变量将存储在本地内存中。本地内存实质上是和全局内存一样在同一块存储区域当中的，其访问特点——高延迟，低带宽。对于2.0以上的设备，本地内存存储在每个SM的一级缓存，或者设备的二级缓存上。

### 共享内存
一个线程块使用的共享内存过多，导致更过的线程块没办法被SM启动，这样影响活跃的线程束数量。共享内存在核函数内声明，生命周期和线程块一致。使用`__syncthreads`可缓解竞争。

声明一个二维浮点数共享内存数组的方法是: `__shared__ float a[size_x][size_y];`

填充静态声明的共享内存: `_shared__ int tile[BDIMY][BDIMX+IPAD];`。唯一要注意的就是索引，当填充了以后我们的行不变，列加宽了，所以索引的时候要相应改变。


动态声明一个共享内存数组，可以使用extern关键字，并在核函数启动时添加第三个参数。注意，动态声明只支持一维数组。
```C++
extern __shared__ int tile[];
kernel<<<grid,block,isize*sizeof(int)>>>(...); // isize就是共享内存要存储的数组的大小。比如一个十个元素的int数组，isize就是10.
```

当多个线程要访问一个存储体的时候，冲突就发生了，注意这里是说访问同一个存储体，而不是同一个地址.???

访问模式查询: 可以通过以下语句，查询是4字节还是8字节：
```C++
cudaError_t cudaDeviceGetSharedMemConfig(cudaSharedMemConfig * pConfig);
```
在可以配置的设备上，可以用下面函数来配置新的存储体大小：
```C++
cudaError_t cudaDeviceSetShareMemConfig(cudaSharedMemConfig config);
```

每个SM上有64KB的片上内存，共享内存和L1共享这64KB，并且可以配置。CUDA为配置一级缓存和共享内存提供以下两种方法：
按设备进行配置(`cudaError_t cudaDeviceSetCacheConfig(cudaFuncCache cacheConfig);`)
按核函数进行配置(`cudaError_t cudaFuncSetCacheConfig(const void* func,enum cudaFuncCacheca cheConfig);`)

一级缓存和共享内存都在同一个片上，但是行为大不相同，共享内存靠的的是存储体来管理数据，而L1则是通过缓存行进行访问。我们对共享内存有绝对的控制权，但是L1的删除工作是硬件完成的。

同步基本方法：障碍、内存栅栏。障碍是所有调用线程等待其余调用线程达到障碍点。内存栅栏，所有调用线程必须等到全部内存修改对其余线程可见时才继续进行。

弱排序内存模型: 核函数内连续两个内存访问指令，如果独立，其不一定哪个先被执行。Volatile修饰符声明一个变量，则对该变量同一时间只能执行一个指令。

##### 内存栅栏???
1. 线程块内
`void __threadfence_block();`
保证同一块中的其他线程对于栅栏前的内存写操作可见

2. 网格级内存栅栏
`void __threadfence();`
挂起调用线程，直到全局内存中所有写操作对相同的网格内的所有线程可见

3. 系统级栅栏，夸系统，包括主机和设备，
`void __threadfence_system();`
挂起调用线程，以保证该线程对全局内存，锁页主机内存和其他设备内存中的所有写操作对全部设备中的线程和主机线程可见。

volatile修饰符声明一个变量，防止编译器优化，volatile声明的变量始终在全局内存中。

##### 共享内存的数据布局
在CPU中，如果用循环遍历二维数组，尤其是双层循环的方式，我们倾向于内层循环对应x，因为这样的访问方式在内存中是连续的。但是GPU的共享内存并不是线性的，而是二维的，分成不同存储体的，并且，并行也不是循环。

我们的数据是按照行放进存储体中的。所以`x[threadIdx.y][threadIdx.x]`这种访问方式是最优的，threadIdx.x在线程束中体现为连续变化的，而对应到共享内存中也是遍历共享内存的同一行的不同列。



### 常量内存
关键字 `__constant__`

常量内存在核函数外，全局范围内声明，并对同一编译单元中的所有核函数可见。主机端代码可以初始化常量内存的,不能被核函数修改。初始化函数如下：
```C++
cudaError_t cudaMemcpyToSymbol(const void* symbol,const void *src,size_t count);
```
当线程束中所有线程都从相同的地址取数据时，常量内存表现较好，但是如果不同的线程取不同地址的数据，常量内存就不那么好了，因为常量内存的读取机制是：
一次读取会广播给所有线程束内的线程。

，只读缓存对于分散访问的更好。当所有线程读取同一地址的时候常量缓存最好，只读缓存这时候效果并不好，只读换粗粒度为32.

### 纹理内存
???
### 全局内存
一般在主机端代码里定义，也可以在设备端定义，不过需要加修饰符，只要不销毁，是和应用程序同生命周期的。全局内存访问是对齐。

### GPU缓存
GPU缓存不可编程，其行为出厂是时已经设定好了。GPU上有4种缓存：一级缓存、二级缓存、只读常量缓存、只读纹理缓存。每个SM都有一个一级缓存，所有SM公用一个二级缓存。每个SM有一个只读常量缓存，只读纹理缓存，它们用于设备内存中提高来自于各自内存空间内的读取性能。

### 静态全局内存

### 内存管理

在数据传输之前，CUDA驱动会锁定页面，或者直接分配固定的主机内存，将主机源数据复制到固定内存上，然后从固定内存传输数据到设备上。下面函数用来分配固定内存：
```C++
cudaError_t cudaMallocHost(void ** devPtr,size_t count);
```
分配count字节的固定内存，这些内存是页面锁定的，可以直接传输到设备的. 固定的主机内存释放使用：
```C++
cudaError_t cudaFreeHost(void *ptr);
```
固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。

### 零拷贝内存

通过以下函数创建零拷贝内存：
```C++
cudaError_t cudaHostAlloc(void ** pHost,size_t count,unsigned int flags);
```
cudaHostAllocDefalt、cudaHostAllocPortable、cudaHostAllocWriteCombined、cudaHostAllocMapped
cudaHostAllocDefalt和cudaMallocHost函数一致，cudaHostAllocPortable函数返回能被所有CUDA上下文使用的固定内存，cudaHostAllocWriteCombined返回写结合内存，在某些设备上这种内存传输效率更高。cudaHostAllocMapped产生零拷贝内存。???

零拷贝内存虽然不需要显式的传递到设备上，但是设备还不能通过pHost直接访问对应的内存地址，设备需要访问主机上的零拷贝内存，需要先获得另一个地址，这个地址帮助设备访问到主机对应的内存，方法是：
```C++
cudaError_t cudaHostGetDevicePointer(void ** pDevice,void * pHost,unsigned flags);
```
pDevice就是设备上访问主机零拷贝内存的指针了。此处flag必须设置为0，具体内容后面有介绍。


### 统一虚拟寻址

设备架构2.0以后，`cudaHostGetDevicePointer`基本上可以不再使用

### 统一内存寻址
CUDA6.0出现统一内存寻址。
```C++
cudaError_t cudaMallocManaged(void ** devPtr,size_t size,unsigned int flags=0);
```
CUDA6.0中设备代码不能调用cudaMallocManaged，只能主机调用，所有托管内存必须在主机代码上动态声明，或者全局静态声明.
页面故障???

### 线程束洗牌指令




# 

