---
layout: post
title:  "omp"
date:   2025-04-22 23:59:18 +0800
categories: [Tech]
excerpt: omp
tags:
  - omp
---

```C++
// Parallel loop
#pragma omp parallel for
for (int i = 0; i < size; ++i) {
    // Code that can be executed in parallel
    data[i] *= 2;  // Example: Doubling each element

    // Code that cannot be executed in parallel; {} is not necessary, it's used to improve readability and avoid unintended behavior.
    #pragma omp critical
    {
        result += data[i];  // Example: Accumulating to a shared variable
    }
}
```

```C++
// Parallel loop with reduction
#pragma omp parallel for reduction(+:result)
for (int i = 0; i < size; ++i) {
    // Code that can be executed in parallel
    data[i] *= 2;  // Example: Doubling each element
    // Reduction operation
    result += data[i];
}
```

Benefits of Using reduction:

1. Reduces overhead of the critical section. 
2. Automatically handles thread-local copies and merging.

Use the reduction clause for simpler operations and critical for more complex shared operations.

### set the number of threads used for parallel execution

```C++
// OpenMP does not guarantee a fixed traversal order.
#pragma omp parallel for num_threads(4)
for (int i = 0; i < size; ++i) {
    data[i] *= 2; // Example operation: doubling each element
    int thread_id = omp_get_thread_num();
    std::cout << "Thread " << thread_id << " processed index " << i << "\n";
}
```

If traversal order is important, use ordered:

```c++
#pragma omp parallel for ordered
for (int i = 0; i < 10; i++) {
    #pragma omp ordered
    printf("Ordered execution: i = %d\n", i);
}
```
